{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# NHANES Ground Truth Distributions\n",
    "\n",
    "## Required Variables (all combinations)\n",
    "1. RIDAGEYR (Age) → 5 bins\n",
    "2. RIAGENDR (Gender)\n",
    "3. RIDRETH1 (Race)\n",
    "4. DMDEDUC2 (Education)\n",
    "5. INDFMPIR (Poverty Income Ratio) → 4 bins\n",
    "6. OCD150 (Work Activity Level)\n",
    "\n",
    "## Additional Variables\n",
    "- SMQ020 (Smoking)\n",
    "\n",
    "## Key Format\n",
    "`RIDAGEYR=20-39__RIAGENDR=Male__RIDRETH1=White`\n",
    "\n",
    "## Minimum Sample Size\n",
    "N >= 50 unique subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from itertools import product\n",
    "\n",
    "load_dotenv()\n",
    "sys.path.append(\"../..\")\n",
    "from src.data.nhanes import load_nhanes_data\n",
    "\n",
    "MIN_SAMPLES = 50\n",
    "\n",
    "df_nhanes = load_nhanes_data()\n",
    "print(f\"Data shape: {df_nhanes.shape}\")\n",
    "print(f\"Unique subjects: {df_nhanes['SEQN'].nunique()}\")\n",
    "print(f\"Columns: {df_nhanes.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore variables\n",
    "print(\"=\" * 60)\n",
    "print(\"Variable Exploration\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n1. RIDAGEYR (Age):\")\n",
    "print(f\"   Range: {df_nhanes['RIDAGEYR'].min()} - {df_nhanes['RIDAGEYR'].max()}\")\n",
    "\n",
    "print(\"\\n2. RIAGENDR (Gender):\")\n",
    "print(df_nhanes['RIAGENDR'].value_counts())\n",
    "\n",
    "print(\"\\n3. RIDRETH1 (Race):\")\n",
    "print(df_nhanes['RIDRETH1'].value_counts())\n",
    "\n",
    "print(\"\\n4. DMDEDUC2 (Education):\")\n",
    "print(df_nhanes['DMDEDUC2'].value_counts())\n",
    "\n",
    "print(\"\\n5. INDFMPIR (Poverty Income Ratio, 0-5 scale):\")\n",
    "print(f\"   Range: {df_nhanes['INDFMPIR'].min():.2f} - {df_nhanes['INDFMPIR'].max():.2f}\")\n",
    "print(f\"   Mean: {df_nhanes['INDFMPIR'].mean():.2f}\")\n",
    "print(f\"   Missing: {df_nhanes['INDFMPIR'].isna().sum()}\")\n",
    "\n",
    "print(\"\\n6. OCD150 (Work Activity):\")\n",
    "print(df_nhanes['OCD150'].value_counts())\n",
    "\n",
    "print(\"\\n7. SMQ020 (Smoking):\")\n",
    "print(df_nhanes['SMQ020'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocessing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create categorical variables\n",
    "df = df_nhanes.copy()\n",
    "\n",
    "# 1. RIDAGEYR: 5 bins using quantiles\n",
    "df[\"age_bin\"] = pd.qcut(df[\"RIDAGEYR\"], q=5, labels=False, duplicates='drop')\n",
    "age_ranges = df.groupby(\"age_bin\", observed=True)[\"RIDAGEYR\"].agg([\"min\", \"max\"])\n",
    "\n",
    "age_labels = {}\n",
    "for idx, row in age_ranges.iterrows():\n",
    "    age_labels[idx] = f\"{int(row['min'])}-{int(row['max'])}\"\n",
    "df[\"RIDAGEYR_cat\"] = df[\"age_bin\"].map(age_labels)\n",
    "\n",
    "print(\"RIDAGEYR bins:\")\n",
    "for idx, label in age_labels.items():\n",
    "    print(f\"  Bin {idx}: {label}\")\n",
    "\n",
    "# 2. RIAGENDR\n",
    "df[\"RIAGENDR_cat\"] = df[\"RIAGENDR\"].map({1.0: \"Male\", 2.0: \"Female\"})\n",
    "\n",
    "# 3. RIDRETH1\n",
    "race_map = {\n",
    "    1.0: \"MexicanAmerican\",\n",
    "    2.0: \"OtherHispanic\",\n",
    "    3.0: \"White\",\n",
    "    4.0: \"Black\",\n",
    "    5.0: \"Other\"\n",
    "}\n",
    "df[\"RIDRETH1_cat\"] = df[\"RIDRETH1\"].map(race_map)\n",
    "\n",
    "# 4. DMDEDUC2\n",
    "edu_map = {\n",
    "    1.0: \"LessThan9th\",\n",
    "    2.0: \"9thTo11th\",\n",
    "    3.0: \"HighSchool\",\n",
    "    4.0: \"SomeCollege\",\n",
    "    5.0: \"CollegeGrad\"\n",
    "}\n",
    "df[\"DMDEDUC2_cat\"] = df[\"DMDEDUC2\"].map(edu_map)\n",
    "\n",
    "# 5. INDFMPIR: Poverty Income Ratio (0-5 scale) -> 4 bins\n",
    "# 0-1: Below poverty line\n",
    "# 1-2.5: Low income\n",
    "# 2.5-4: Middle income\n",
    "# 4-5: High income\n",
    "def map_income(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    elif x < 1:\n",
    "        return \"BelowPoverty\"\n",
    "    elif x < 2.5:\n",
    "        return \"LowIncome\"\n",
    "    elif x < 4:\n",
    "        return \"MiddleIncome\"\n",
    "    else:\n",
    "        return \"HighIncome\"\n",
    "\n",
    "df[\"INDFMPIR_cat\"] = df[\"INDFMPIR\"].apply(map_income)\n",
    "print(\"\\nINDFMPIR distribution:\")\n",
    "print(df[\"INDFMPIR_cat\"].value_counts())\n",
    "\n",
    "# 6. OCD150\n",
    "activity_map = {\n",
    "    1.0: \"Sedentary\",\n",
    "    2.0: \"Light\",\n",
    "    3.0: \"Moderate\",\n",
    "    4.0: \"Heavy\"\n",
    "}\n",
    "df[\"OCD150_cat\"] = df[\"OCD150\"].map(activity_map)\n",
    "\n",
    "# 7. SMQ020\n",
    "df[\"SMQ020_cat\"] = df[\"SMQ020\"].map({1.0: \"Yes\", 2.0: \"No\"})\n",
    "\n",
    "print(\"\\nPreprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_categories",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable mapping: original column name -> categorical column name\n",
    "var_mapping = {\n",
    "    \"RIDAGEYR\": \"RIDAGEYR_cat\",\n",
    "    \"RIAGENDR\": \"RIAGENDR_cat\",\n",
    "    \"RIDRETH1\": \"RIDRETH1_cat\",\n",
    "    \"DMDEDUC2\": \"DMDEDUC2_cat\",\n",
    "    \"INDFMPIR\": \"INDFMPIR_cat\",\n",
    "    \"OCD150\": \"OCD150_cat\",\n",
    "    \"SMQ020\": \"SMQ020_cat\"\n",
    "}\n",
    "\n",
    "cat_cols = list(var_mapping.values())\n",
    "\n",
    "print(\"Category summary:\")\n",
    "print(\"=\" * 60)\n",
    "total_combinations = 1\n",
    "for orig_name, cat_name in var_mapping.items():\n",
    "    n_cats = df[cat_name].dropna().nunique()\n",
    "    cats = sorted(df[cat_name].dropna().unique().tolist())\n",
    "    print(f\"{orig_name}: {n_cats} categories - {cats}\")\n",
    "    total_combinations *= n_cats\n",
    "\n",
    "print(f\"\\nTheoretical max combinations (7 vars): {total_combinations:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute_stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stats(data):\n",
    "    \"\"\"Compute statistics for height and weight from unique subjects.\"\"\"\n",
    "    # Drop duplicate subjects to get accurate counts\n",
    "    unique_data = data.drop_duplicates(subset=[\"SEQN\"])\n",
    "    \n",
    "    if len(unique_data) < MIN_SAMPLES:\n",
    "        return None\n",
    "    \n",
    "    height_data = unique_data[\"BMXHT\"].dropna()\n",
    "    weight_data = unique_data[\"BMXWT\"].dropna()\n",
    "    \n",
    "    if len(height_data) < MIN_SAMPLES or len(weight_data) < MIN_SAMPLES:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        \"height_mean\": round(float(height_data.mean()), 2),\n",
    "        \"height_std\": round(float(height_data.std()), 2),\n",
    "        \"height_var\": round(float(height_data.var()), 2),\n",
    "        \"weight_mean\": round(float(weight_data.mean()), 2),\n",
    "        \"weight_std\": round(float(weight_data.std()), 2),\n",
    "        \"weight_var\": round(float(weight_data.var()), 2),\n",
    "        \"n\": int(len(unique_data))\n",
    "    }\n",
    "\n",
    "def make_key(var_value_pairs):\n",
    "    \"\"\"Create key in format: RIDAGEYR=20-39__RIAGENDR=Male__...\"\"\"\n",
    "    return \"__\".join([f\"{var}={val}\" for var, val in var_value_pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_distributions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build all distributions\n",
    "df_valid = df.dropna(subset=[\"BMXHT\", \"BMXWT\"])\n",
    "print(f\"Rows with valid height/weight: {len(df_valid)}\")\n",
    "print(f\"Unique subjects: {df_valid['SEQN'].nunique()}\")\n",
    "print(f\"Minimum sample size: {MIN_SAMPLES}\")\n",
    "\n",
    "distributions = {}\n",
    "\n",
    "# Overall\n",
    "stats = compute_stats(df_valid)\n",
    "if stats:\n",
    "    distributions[\"Overall\"] = stats\n",
    "    print(f\"\\nOverall: n={stats['n']} unique subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_single",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single variable marginals\n",
    "print(\"\\nComputing single variable marginals...\")\n",
    "single_count = 0\n",
    "\n",
    "for orig_name, cat_name in var_mapping.items():\n",
    "    for val in df_valid[cat_name].dropna().unique():\n",
    "        subset = df_valid[df_valid[cat_name] == val]\n",
    "        stats = compute_stats(subset)\n",
    "        if stats:\n",
    "            key = make_key([(orig_name, val)])\n",
    "            distributions[key] = stats\n",
    "            single_count += 1\n",
    "\n",
    "print(f\"  Added {single_count} single variable entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_pairs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two variable combinations\n",
    "print(\"\\nComputing two variable combinations...\")\n",
    "pair_count = 0\n",
    "\n",
    "# Define useful pairs\n",
    "pairs = [\n",
    "    (\"RIAGENDR\", \"RIDAGEYR\"),\n",
    "    (\"RIAGENDR\", \"RIDRETH1\"),\n",
    "    (\"RIDAGEYR\", \"RIDRETH1\"),\n",
    "    (\"RIAGENDR\", \"SMQ020\"),\n",
    "    (\"RIAGENDR\", \"DMDEDUC2\"),\n",
    "    (\"RIDAGEYR\", \"DMDEDUC2\"),\n",
    "]\n",
    "\n",
    "for var1, var2 in pairs:\n",
    "    cat1, cat2 = var_mapping[var1], var_mapping[var2]\n",
    "    for val1 in df_valid[cat1].dropna().unique():\n",
    "        for val2 in df_valid[cat2].dropna().unique():\n",
    "            subset = df_valid[(df_valid[cat1] == val1) & (df_valid[cat2] == val2)]\n",
    "            stats = compute_stats(subset)\n",
    "            if stats:\n",
    "                key = make_key([(var1, val1), (var2, val2)])\n",
    "                distributions[key] = stats\n",
    "                pair_count += 1\n",
    "\n",
    "print(f\"  Added {pair_count} two variable entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_triples",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three variable combinations (Gender x Age x Race)\n",
    "print(\"\\nComputing three variable combinations...\")\n",
    "triple_count = 0\n",
    "\n",
    "for gender in df_valid[\"RIAGENDR_cat\"].dropna().unique():\n",
    "    for age in df_valid[\"RIDAGEYR_cat\"].dropna().unique():\n",
    "        for race in df_valid[\"RIDRETH1_cat\"].dropna().unique():\n",
    "            subset = df_valid[\n",
    "                (df_valid[\"RIAGENDR_cat\"] == gender) & \n",
    "                (df_valid[\"RIDAGEYR_cat\"] == age) & \n",
    "                (df_valid[\"RIDRETH1_cat\"] == race)\n",
    "            ]\n",
    "            stats = compute_stats(subset)\n",
    "            if stats:\n",
    "                key = make_key([\n",
    "                    (\"RIAGENDR\", gender),\n",
    "                    (\"RIDAGEYR\", age),\n",
    "                    (\"RIDRETH1\", race)\n",
    "                ])\n",
    "                distributions[key] = stats\n",
    "                triple_count += 1\n",
    "\n",
    "print(f\"  Added {triple_count} three variable entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build_full_6vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full 6 variable combinations\n",
    "print(\"\\nComputing full 6 variable combinations...\")\n",
    "main_vars = [\"RIDAGEYR\", \"RIAGENDR\", \"RIDRETH1\", \"DMDEDUC2\", \"INDFMPIR\", \"OCD150\"]\n",
    "main_cats = [var_mapping[v] for v in main_vars]\n",
    "\n",
    "df_main = df_valid.dropna(subset=main_cats)\n",
    "print(f\"Rows with all 6 main variables: {len(df_main)}\")\n",
    "print(f\"Unique subjects: {df_main['SEQN'].nunique()}\")\n",
    "\n",
    "var_values = {v: sorted(df_main[var_mapping[v]].dropna().unique().tolist()) for v in main_vars}\n",
    "\n",
    "full_count = 0\n",
    "for combo in product(*[var_values[v] for v in main_vars]):\n",
    "    mask = pd.Series([True] * len(df_main), index=df_main.index)\n",
    "    for var, val in zip(main_vars, combo):\n",
    "        mask &= (df_main[var_mapping[var]] == val)\n",
    "    \n",
    "    subset = df_main[mask]\n",
    "    stats = compute_stats(subset)\n",
    "    \n",
    "    if stats:\n",
    "        key = make_key(list(zip(main_vars, combo)))\n",
    "        distributions[key] = stats\n",
    "        full_count += 1\n",
    "\n",
    "print(f\"  Added {full_count} full 6 variable entries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Distribution Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total entries: {len(distributions)}\")\n",
    "print(f\"Minimum sample size: {MIN_SAMPLES}\")\n",
    "\n",
    "json_str = json.dumps(distributions, indent=2)\n",
    "print(f\"Estimated JSON size: {len(json_str) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create_metadata",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create final output with metadata\n",
    "output = {\n",
    "    \"metadata\": {\n",
    "        \"source\": \"NHANES August2021-August2023\",\n",
    "        \"description\": \"Ground truth distributions for height (cm) and weight (kg)\",\n",
    "        \"total_unique_subjects\": int(df_nhanes[\"SEQN\"].nunique()),\n",
    "        \"min_samples_per_entry\": MIN_SAMPLES,\n",
    "        \"variables\": {\n",
    "            \"RIDAGEYR\": {\n",
    "                \"description\": \"Age in years (binned by quantiles)\",\n",
    "                \"values\": list(age_labels.values())\n",
    "            },\n",
    "            \"RIAGENDR\": {\n",
    "                \"description\": \"Gender\",\n",
    "                \"values\": [\"Male\", \"Female\"]\n",
    "            },\n",
    "            \"RIDRETH1\": {\n",
    "                \"description\": \"Race/Ethnicity\",\n",
    "                \"values\": [\"MexicanAmerican\", \"OtherHispanic\", \"White\", \"Black\", \"Other\"]\n",
    "            },\n",
    "            \"DMDEDUC2\": {\n",
    "                \"description\": \"Education level\",\n",
    "                \"values\": [\"LessThan9th\", \"9thTo11th\", \"HighSchool\", \"SomeCollege\", \"CollegeGrad\"]\n",
    "            },\n",
    "            \"INDFMPIR\": {\n",
    "                \"description\": \"Family poverty income ratio (0-5 scale, binned)\",\n",
    "                \"values\": [\"BelowPoverty\", \"LowIncome\", \"MiddleIncome\", \"HighIncome\"],\n",
    "                \"bins\": \"0-1: BelowPoverty, 1-2.5: LowIncome, 2.5-4: MiddleIncome, 4-5: HighIncome\"\n",
    "            },\n",
    "            \"OCD150\": {\n",
    "                \"description\": \"Work activity level\",\n",
    "                \"values\": [\"Sedentary\", \"Light\", \"Moderate\", \"Heavy\"]\n",
    "            },\n",
    "            \"SMQ020\": {\n",
    "                \"description\": \"Smoked 100+ cigarettes in life\",\n",
    "                \"values\": [\"Yes\", \"No\"]\n",
    "            }\n",
    "        },\n",
    "        \"key_format\": \"COLNAME=value__COLNAME=value (e.g., RIAGENDR=Male__RIDAGEYR=18-37)\"\n",
    "    },\n",
    "    \"distributions\": distributions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_json",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON\n",
    "output_dir = \"../../data/processed\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = f\"{output_dir}/nhanes_ground_truth.json\"\n",
    "with open(output_path, \"w\") as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print(f\"File size: {os.path.getsize(output_path) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview sample entries\n",
    "print(\"Sample entries:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sample_keys = list(distributions.keys())[:10]\n",
    "\n",
    "for key in sample_keys:\n",
    "    d = distributions[key]\n",
    "    print(f\"\\n{key}\")\n",
    "    print(f\"  Height: {d['height_mean']} +/- {d['height_std']} cm\")\n",
    "    print(f\"  Weight: {d['weight_mean']} +/- {d['weight_std']} kg\")\n",
    "    print(f\"  N: {d['n']} unique subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usage_example",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example\n",
    "print(\"\\nUsage Example:\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "import json\n",
    "\n",
    "with open('data/processed/nhanes_ground_truth.json', 'r') as f:\n",
    "    gt = json.load(f)\n",
    "\n",
    "# Get distribution for a 18-37 year old male\n",
    "key = 'RIAGENDR=Male__RIDAGEYR=18-37'\n",
    "if key in gt['distributions']:\n",
    "    stats = gt['distributions'][key]\n",
    "    print(f\"Height: {stats['height_mean']} +/- {stats['height_std']} cm\")\n",
    "    print(f\"Weight: {stats['weight_mean']} +/- {stats['weight_std']} kg\")\n",
    "    print(f\"N: {stats['n']} unique subjects\")\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
